# Domain-Driven Hybrid Anomaly Detection for Streaming Behavior

![Python](https://img.shields.io/badge/python-3.10-blue) ![PyTorch](https://img.shields.io/badge/pytorch-2.0-orange) ![XGBoost](https://img.shields.io/badge/xgboost-1.7-red)

## ğŸ“– Project Overview
This repository demonstrates a domain-driven, Netflix-inspired approach to anomaly detection that simulates streaming behavior using an open credit-card dataset. The core idea: combine domain heuristics with semi-supervised and supervised models to build a practical, production-minded anomaly detection flow.

Key components:
- Domain-driven heuristics / rules to bootstrap labels
- Semi-supervised Autoencoder to produce reconstruction-based anomaly scores and embeddings
- Supervised "judge" (XGBoost) that combines engineered features + autoencoder outputs to produce final anomaly probabilities

This hybrid approach aims to improve detection accuracy and reduce false positives compared to heuristics-only systems.

Working Notebook:https://github.com/deepthivj-aiml/Hybrid-anomaly-detection-pipeline-/blob/main/Anomaly_Detection_Pipeline.ipynb
Project structure: Work in progress

---

## ğŸ¯ Objectives
1. Simulate streaming fraud/anomaly detection with public data.  
2. Bootstrap labels with domain heuristics.  
3. Engineer behavioral features rather than relying only on raw stats.  
4. Train a semi-supervised Autoencoder for anomaly scoring.  
5. Use XGBoost as a supervised judge combining embeddings, recon errors and features.  
6. Evaluate detection effectiveness (precision/recall/F1/AUC etc.).

---

## ğŸ—‚ï¸ Dataset (demo)
- Source: Credit Card Fraud Detection dataset (OpenML, `fetch_openml("creditcard")`).  
- Demo subset: 50,000 rows (configurable) for quick experiments.  
- Example features used: `Amount`, `V1`â€“`V6` (numeric PCA-like components in original dataset).  
- Heuristic pseudo-labels simulate streaming â€œunexpected behaviorâ€ (e.g., very large amounts, unusual combinations of V-features).

---

## âš™ï¸ Pipeline Overview

1. Data loading (OpenML or local CSV/Parquet)  
2. Domain heuristics create pseudo-labels for bootstrapping  
3. Feature engineering (scaling, rolling stats / session summaries where applicable)  
4. Train Autoencoder (semi-supervised) on normal-ish data to learn reconstruction; compute recon error + embeddings  
5. Train XGBoost judge using features + autoencoder outputs  
6. Evaluate end-to-end: AUC-ROC, Precision@k, F1, confusion matrices, error histograms

---

## ğŸ”§ Tech Stack
- Python 3.10
- PyTorch (Autoencoder)
- XGBoost (Judge)
- pandas, numpy, scikit-learn, matplotlib, seaborn, openml
- Colab-friendly notebooks included

---

## Repository structure
Hybrid-Anomaly-Detection-Pipeline/
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml            # Main pipeline config
â”‚   â”œâ”€â”€ autoencoder.yaml       # Autoencoder-specific params
â”‚   â”œâ”€â”€ judge.yaml             # XGBoost judge params
â”‚   â””â”€â”€ infer.yaml             # Inference / embedding generation params
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # Place raw dataset CSVs here
â”‚   â”‚   â””â”€â”€ creditcard_50k.csv
â”‚   â””â”€â”€ processed/             # Optional: preprocessed train/val/test splits
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py              # Constants: DATA_URL, paths, AE_EPOCHS, etc.
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ load_data.py       # download_dataset(), load_sample(n_samples)
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â””â”€â”€ feature_engineering.py  # heuristic_labeling(df), extract_features(df)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ autoencoder.py     # AE nn.Module
â”‚   â”‚   â””â”€â”€ judge.py           # create_xgb_classifier() â†’ returns XGBClassifier
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ train_pipeline.py  # run_pipeline() orchestrator
â”‚   â””â”€â”€ evaluation/
â”‚       â””â”€â”€ evaluate.py        # evaluate_model(), plot_ae_errors()
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_openml_subset.py  # Downloads demo subset
â”‚   â”œâ”€â”€ run_pipeline.sh            # Run entire pipeline
â”‚   â”œâ”€â”€ train_autoencoder.py       # Train only AE
â”‚   â”œâ”€â”€ generate_embeddings.py     # Extract embeddings
â”‚   â”œâ”€â”€ train_judge.py             # Train only XGBoost judge
â”‚   â””â”€â”€ evaluate.py                # Evaluation script
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Anomaly_Detection_Pipeline.ipynb  # End-to-end demo / Colab-friendly
â”‚
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ autoencoder/  # AE checkpoints, logs
â”‚   â”œâ”€â”€ judge/        # XGB model dumps, pipeline metadata
â”‚   â”œâ”€â”€ features/     # Dataset + embeddings + recon errors
â”‚   â””â”€â”€ reports/      # Metrics, plots
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ lint.yml
â”‚       â””â”€â”€ test.yml
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE


---

## Quickstart

1. Clone the repo
```bash
git clone https://github.com/deepthivj-aiml/Hybrid-anomaly-detection-pipeline-.git
cd Hybrid-anomaly-detection-pipeline-
```

2. Create & activate virtualenv, then install dependencies:
```bash
python -m venv .venv
source .venv/bin/activate    # macOS / Linux
.venv\Scripts\activate       # Windows (PowerShell)
pip install -r requirements.txt
```

3. Download demo subset from OpenML (example script provided):
```bash
python scripts/download_openml_subset.py --dataset creditcard --n_rows 50000 --out data/raw/creditcard_50k.csv
```

4. Run the end-to-end demo:
```bash
bash scripts/run_pipeline.sh --config config/config.yaml
```
Or run the steps individually:
```bash
python scripts/train_autoencoder.py --config config/autoencoder.yaml
python scripts/generate_embeddings.py --config config/infer.yaml
python scripts/train_judge.py --config config/judge.yaml
python scripts/evaluate.py --config config/eval.yaml
```

---

## Configuration
Pipeline behavior is controlled via YAML files in `config/`. Typical sections:
- `data`: raw/processed paths, sample size, target column
- `preprocessing`: scaler type, columns to use
- `autoencoder`: model arch (latent dim), epochs, batch_size, learning_rate, seed
- `judge`: XGBoost params (n_estimators, max_depth, learning_rate), early_stopping
- `artifacts`: output directory, filenames

Example:
```yaml
data:
  raw_path: data/raw/creditcard_50k.csv
  processed_dir: data/processed
  target_col: is_anomaly
autoencoder:
  latent_dim: 16
  epochs: 50
  batch_size: 128
  learning_rate: 1e-3
judge:
  n_estimators: 200
  max_depth: 6
  learning_rate: 0.1
artifacts:
  output_dir: artifacts/
```

---

## Data format & recommended layout
- Tabular CSV or Parquet, rows = observations, columns = features.  
- If labels exist: binary column `is_anomaly` with 1 = anomaly, 0 = normal.  
- For streaming simulation, include a timestamp or session id column if you want to compute behavioral aggregations.

Recommended:
```
data/
  raw/
    creditcard_50k.csv
  processed/
    train.parquet
    val.parquet
    test.parquet
```

---

## Feature engineering suggestions
- Standard scaling for numeric features  
- Add engineered behavioral features:
  - rolling mean/std over last N events (if timestamped)
  - session totals / averages
  - time-since-last-event
- Autoencoder: use embeddings and reconstruction error (L1/L2) as features for the judge

---

## Training & evaluation details
- Autoencoder training: minimize reconstruction loss on mostly-normal data. Use recon error as anomaly score.
- Judge training: supervised XGBoost that combines features + recon error + embeddings.
- Metrics:
  - AUC-ROC, Average Precision
  - Precision@k (top-k anomalies)
  - Precision, Recall, F1 at selected thresholds
- Visuals:
  - Histograms of reconstruction errors
  - Precision/Recall curves
  - Feature importance from XGBoost

Reproducibility: set `seed` in configs so numpy, torch, and random are fixed.

---

## Notebooks & demos
- `notebooks/` contains:
  - A Colab-friendly demo that downloads OpenML data, creates heuristics, trains the autoencoder, trains the judge, and evaluates results.
  - Exploratory notebooks for feature design and error analysis.

---

## Artifacts
Default outputs are written to `artifacts/`:
- `artifacts/autoencoder/` â€” model checkpoints, training logs
- `artifacts/judge/` â€” XGBoost model dumps, feature pipeline metadata
- `artifacts/features/` â€” datasets augmented with embeddings and recon errors
- `artifacts/reports/` â€” metrics, plots, and evaluation reports

---

## Development, testing & CI
- Unit tests:
```bash
pytest
```
- Linting & formatting:
```bash
flake8 src
black .
```
- CI: see `.github/workflows/` for lint & test jobs.

---

## Practical recommendations for streaming
- Use heuristics to flag suspicious events and collect human feedback to grow labeled data.
- Use the autoencoder scores for continuous monitoring and to prioritize events for labeling.
- Retrain judge periodically as more labeled examples arrive; consider online / incremental learning for judge if data changes fast.
- Monitor model drift (score distributions) and data quality.

---

## Contributing
Contributions welcome:
1. Open an issue describing your proposal/bug.
2. Create a branch off `main`.
3. Add tests for new functionality.
4. Submit a PR with a clear description and changelog entry.

Please follow existing code style and include reproducible examples for new features.

---

## License
Add a `LICENSE` file for the repository. Suggested: MIT License for an open-source demo.

---

## Contact
Maintainer: deepthivj-aiml (GitHub)  
For questions, issues, or collaboration ideas, please open an issue in this repository.

---

## Citation
If you use this pipeline in research or demos, please cite the repository and include a link to the commit used.
